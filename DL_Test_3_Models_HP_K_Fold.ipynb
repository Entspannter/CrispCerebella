{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Test_3_Models_HP_K_Fold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Entspannter/CrispCerebella/blob/main/DL_Test_3_Models_HP_K_Fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDFVMFUkd3kp",
        "outputId": "8dc1eb03-3776-4c05-b11b-7157e8380efd"
      },
      "source": [
        "!git clone https://github.com/Entspannter/CrispCerebella.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CrispCerebella'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 160 (delta 56), reused 126 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (160/160), 75.57 MiB | 13.70 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "Checking out files: 100% (145/145), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsuTc0aaQDgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f83d4c-eded-4253-8bd9-f039892e7331"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51kB 14.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71kB 11.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81kB 12.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 6.5MB/s \n",
            "\u001b[?25h  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjdmgUHLCKhe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os \n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import array\n",
        "from numpy import vstack\n",
        "from numpy import dstack\n",
        "from numpy import unique\n",
        "from scipy import stats\n",
        "from matplotlib import pyplot\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras_tuner\n",
        "from keras_tuner import HyperModel\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtd1aHM9xvL0"
      },
      "source": [
        "# Functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO1PkwUBCObh",
        "outputId": "14ba3a8a-af7e-44f5-a97a-8f5d1ef72a03"
      },
      "source": [
        "#Build a Dataloader function\n",
        "\n",
        "def dataloader(d_path):\n",
        "\tdataframe = read_csv(d_path, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "data = dataloader('/content/CrispCerebella/Dataset/UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt')\n",
        "\n",
        "print(\"Shape of Total_Acc_y_train:\", data.shape)\n",
        "\n",
        "# function to load a group of data and create a 3 dimensional tensor out of it\n",
        "def dataloader_group(all_files, directory=''):\n",
        "\tdatalist = list()\n",
        " # for each element in the filelist we load each file seperately and append its data to a list\n",
        "\tfor elem in all_files:\n",
        "\t\tdata = dataloader(directory + elem)\n",
        "\t\tdatalist.append(data)\n",
        "\t# create a 3 dimensional tensor out of the individual data files\n",
        "\tdatalist = dstack(datalist)\n",
        "\treturn datalist\n",
        "\n",
        "# load all acc data into a 3 dimensional tensor \n",
        "total_acc_xyz = dataloader_group(['total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt'], directory='/content/CrispCerebella/Dataset/UCI HAR Dataset/train/Inertial Signals/')\n",
        "print(\"3D Form of Total Acc Data\",total_acc_xyz.shape)\n",
        "\n",
        "# create a train and test group out of the data\n",
        "def datasetloader(train_test_var, directory=''):\n",
        "\n",
        "  \n",
        "\tfilepath = directory + train_test_var + '/Inertial Signals/'\n",
        "\tfilenames = sorted(os.listdir(filepath))\n",
        "\n",
        "\t# load X data (input)\n",
        "\tX = dataloader_group(filenames, filepath)\n",
        "\t# load output labels\n",
        "\ty = dataloader(directory + train_test_var + '/y_'+train_test_var+'.txt')\n",
        "\treturn X, y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Total_Acc_y_train: (7352, 128)\n",
            "3D Form of Total Acc Data (7352, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eogqV-b2Chg_"
      },
      "source": [
        "# load the dataset, returns train and test X and y elements\n",
        "def transform_dataset(trainX, trainy, testX, testy):\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmw2MBbCvp1G"
      },
      "source": [
        "def HP_Search(hypermodel ,MaxTrial, Num_Epochs_Search, Train_X, Train_y, ID):\n",
        "# Define the tuner \n",
        "  tuner = keras_tuner.BayesianOptimization(\n",
        "    hypermodel,\n",
        "    objective = 'val_accuracy',\n",
        "    max_trials = MaxTrial,\n",
        "    tuner_id= ID,\n",
        "    overwrite = True\n",
        ")\n",
        "  # Define an early stop \n",
        "  es = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 2, patience = 3)\n",
        "\n",
        "  # Start the search og hyperparemeters\n",
        "  tuner.search(Train_X, Train_y, epochs = Num_Epochs_Search, validation_split = 0.2,callbacks=[es])\n",
        "\n",
        "  # Get the tuned hyperparemters \n",
        "  best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "  print(\"[The tuned hyperparemters]:\", best_hps.get_config()['values'])\n",
        "\n",
        "  # build a new model with the best hyperparemters\n",
        "  model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "  return model, best_hps"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmDtpbS52l5x"
      },
      "source": [
        "def K_Fold_CV (X, y, Model_Class, Model_Name, Input_Shape, Num_Outputs, Max_Trials, Num_Epochs_Search, Num_Epochs_Fit, Num_K_Folds):\n",
        "\n",
        "  kf = KFold(n_splits = Num_K_Folds, random_state=None)\n",
        "  acc_score = []\n",
        "  k = 0\n",
        "  for train_index , test_index in kf.split(X):\n",
        "      print(\"Statring fold number {}\". format(k+1))\n",
        "      X_train , X_test = X[train_index,:],X[test_index,:]\n",
        "      y_train , y_test = y[train_index] , y[test_index]\n",
        "\n",
        "      hypermodel = Model_Class(Input_Shape, Num_Outputs)\n",
        "\n",
        "      Best_Model, best_hp = HP_Search(hypermodel, Max_Trials, Num_Epochs_Search, X_train, y_train, \"Tuner_\"+str(Model_Name))\n",
        "\n",
        "      Best_Model.fit(X_train, y_train, epochs = Num_Epochs_Fit, validation_split = 0.2)\n",
        "\n",
        "      eval_result = Best_Model.evaluate(X_test, y_test)\n",
        "\n",
        "      test_acc = eval_result[1]\n",
        "\n",
        "      acc_score.append(test_acc)\n",
        "\n",
        "      if k != 0:\n",
        "        if test_acc > acc_score[k-1]:\n",
        "          print(\"{} > {} \". format(test_acc,acc_score[k-1]))\n",
        "          Best_HP = best_hp\n",
        "          print(\"Overriding the HP\")\n",
        "\n",
        "      k += 1\n",
        "      print(\"Fold number {} is done\". format(k+1))\n",
        "\n",
        "\n",
        "\n",
        "  avg_acc_score = sum(acc_score)/Num_K_Folds\n",
        "\n",
        "  print('Accuracy of each fold - {}'.format(acc_score))\n",
        "  print('Avg accuracy : {}'.format(avg_acc_score))\n",
        "\n",
        "  return acc_score, avg_acc_score, Best_HP"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCHyILzBi7H_"
      },
      "source": [
        "def evaluate_model(trainX, trainy, testX, testy, Input_Shape, Num_Outputs, Best_HP, Model_Class, Num_Epochs_Fit, Batch_Size):\n",
        "\n",
        "\t# create a new instace of the model class\n",
        "\tmodel = Model_Class(Input_Shape, Num_Outputs)\n",
        "\n",
        "\t# Build a new model with the best hyperparameters\n",
        "\tBest_Model = model.build(Best_HP)\n",
        " \n",
        "\t# Fit the model \n",
        "\tBest_Model.fit(trainX, trainy, epochs = Num_Epochs_Fit, validation_split = 0.2)\n",
        " \n",
        "\t# evaluate model\n",
        "\t_, accuracy = Best_Model.evaluate(testX, testy, batch_size = Batch_Size, verbose=0)\n",
        " \n",
        "\tprint(\"The accureay of the model is {}\". format(accuracy))\n",
        " \n",
        "\treturn Best_Model, accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7appDXUy1JI"
      },
      "source": [
        "# Stacked LSTM - 2 Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJuMjx4SxsuO",
        "outputId": "cb0cafd1-b9f6-4274-94ff-911f44de07a2"
      },
      "source": [
        "# load all train\n",
        "trainX, trainy = datasetloader('train', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of training Data:\",trainX.shape, trainy.shape)\n",
        "# load all test\n",
        "testX, testy = datasetloader('test', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of test Data:\",testX.shape, testy.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training Data: (7352, 128, 9) (7352, 1)\n",
            "Shape of test Data: (2947, 128, 9) (2947, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU795kcJ_1ky"
      },
      "source": [
        "class LSTMStacked(HyperModel):\n",
        "    def __init__(self, input_shape,n_outputs):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "    def build(self, hp):\n",
        "\n",
        "        model = keras.Sequential()\n",
        "\n",
        "        model.add(LSTM(\n",
        "                        units=hp.Int(\n",
        "                            'Units_LSTM_1',\n",
        "                            min_value=32,\n",
        "                            max_value=512,\n",
        "                            step=32,\n",
        "                            default=128\n",
        "                        ),\n",
        "                       input_shape=self.input_shape,\n",
        "                       return_sequences = True\n",
        "                    )\n",
        "                )\n",
        "        \n",
        "\n",
        "        model.add(\n",
        "            Dropout(rate=hp.Float(\n",
        "                'dropout_1',\n",
        "                min_value=0.0,\n",
        "                max_value=0.5,\n",
        "                default=0.25,\n",
        "                step=0.05,\n",
        "                    )\n",
        "                  )\n",
        "                )\n",
        "        \n",
        "\n",
        "\n",
        "        model.add(LSTM(\n",
        "                        units=hp.Int(\n",
        "                            'Units_LSTM_2',\n",
        "                            min_value=32,\n",
        "                            max_value=512,\n",
        "                            step=32,\n",
        "                            default=128\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "        \n",
        "\n",
        "        model.add(\n",
        "            Dropout(rate=hp.Float(\n",
        "                'dropout_2',\n",
        "                min_value=0.0,\n",
        "                max_value=0.5,\n",
        "                default=0.25,\n",
        "                step=0.05,\n",
        "                    )\n",
        "                  )\n",
        "                )\n",
        "        \n",
        "\n",
        "\n",
        "        model.add(\n",
        "            Dense(\n",
        "                units=hp.Int(\n",
        "                    'units',\n",
        "                    min_value=64,\n",
        "                    max_value=512,\n",
        "                    step=32,\n",
        "                    default=128\n",
        "                ),\n",
        "                activation=hp.Choice(\n",
        "                    'dense_activation',\n",
        "                    values=['relu', 'tanh', 'sigmoid'],\n",
        "                    default='relu'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        model.add(Dense(self.n_outputs, activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(\n",
        "                hp.Float(\n",
        "                    'learning_rate',\n",
        "                    min_value=1e-4,\n",
        "                    max_value=1e-2,\n",
        "                    sampling='LOG',\n",
        "                    default=1e-3\n",
        "                )\n",
        "            ),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SlTPBkt7cIV",
        "outputId": "788e03b8-4433-48ff-8824-c0c1e4e4b5df"
      },
      "source": [
        "trainX, trainy, testX, testy = transform_dataset(trainX, trainy, testX, testy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhqzYaMr7fHw"
      },
      "source": [
        "n_timesteps, n_features, N_OUTPUTS = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\n",
        "n_steps, n_length = 4, 32"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBucICWG7mA0"
      },
      "source": [
        "INPUT_SHAPE=(n_timesteps,n_features)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYWm4U5A4ZdJ"
      },
      "source": [
        "Num_Epochs_Search = 40\n",
        "Num_Epochs_Fit = 40\n",
        "Max_Trials = 10\n",
        "Num_K_Folds = 5\n",
        "Model_Name_LSTM = \"LSTM\"\n",
        "batch_size = 64"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9w1q59Ojg7H"
      },
      "source": [
        "X = np.concatenate((trainX, testX),axis=0)\n",
        "\n",
        "y = np.concatenate((trainy, testy),axis=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpYbVGS0pYxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bab81e4-9cb0-422d-e622-0bc9329053d0"
      },
      "source": [
        "acc_score_LSTM , avg_acc_score_LSTM, Best_HP_LSTM = K_Fold_CV(X, \n",
        "                                             y, \n",
        "                                             LSTMStacked, \n",
        "                                             Model_Name_LSTM, \n",
        "                                             INPUT_SHAPE,\n",
        "                                             N_OUTPUTS,\n",
        "                                             Max_Trials,\n",
        "                                             Num_Epochs_Search,\n",
        "                                             Num_Epochs_Fit, \n",
        "                                             Num_K_Folds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statring fold number 1\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "Units_LSTM_1      |416               |?                 \n",
            "dropout_1         |0.15              |?                 \n",
            "Units_LSTM_2      |512               |?                 \n",
            "dropout_2         |0.35              |?                 \n",
            "units             |128               |?                 \n",
            "dense_activation  |relu              |?                 \n",
            "learning_rate     |0.00010174        |?                 \n",
            "\n",
            "Epoch 1/40\n",
            "  6/206 [..............................] - ETA: 25s - loss: 1.7728 - accuracy: 0.2865WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0562s vs `on_train_batch_end` time: 0.0693s). Check your callbacks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNxxIgsJy3TM"
      },
      "source": [
        "Best_HP_LSTM.get_config()['values']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjomVNRziWpQ"
      },
      "source": [
        "# Build a new model with the HP, train it with the inital training set and eveluate it with the test set \n",
        "\n",
        "BestModelLSTM, LSTM_accuracy = evaluate_model(trainX,\n",
        "                               trainy,\n",
        "                               testX,\n",
        "                               testy,\n",
        "                               INPUT_SHAPE,\n",
        "                               N_OUTPUTS,\n",
        "                               Best_HP_LSTM,\n",
        "                               LSTMStacked,\n",
        "                               Num_Epochs_Fit,\n",
        "                               batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8R2AnrFVA_w"
      },
      "source": [
        "Best_Model_LSTM.save(\"/content/CrispCerebella/Models/Final_Model_LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJyMXfrQ67RT"
      },
      "source": [
        "### For Later Predictions:\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c1e4yvCcWCt"
      },
      "source": [
        "''''from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "prediction = np.argmax(Best_Model_LSTM.predict(testX), axis=-1)\n",
        "print(prediction)\n",
        "\n",
        "prediction = prediction.reshape(prediction.shape[0],1)\n",
        "prediction = prediction+1\n",
        "\n",
        "report = classification_report(testy, prediction)\n",
        "print(report)''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKVB7CrJMWZM"
      },
      "source": [
        "#ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY4pndsYfGv4"
      },
      "source": [
        "trainX, trainy = datasetloader('train', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of training Data:\",trainX.shape, trainy.shape)\n",
        "# load all test\n",
        "testX, testy = datasetloader('test', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of test Data:\",testX.shape, testy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKr1VRin4jdu"
      },
      "source": [
        "class ConvLSTM(HyperModel):\n",
        "    def __init__(self, input_shape,n_outputs):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "    def build(self, hp):\n",
        "\n",
        "\n",
        "        model = keras.Sequential()\n",
        "\n",
        "        model.add(\n",
        "            ConvLSTM2D(\n",
        "                filters=hp.Choice(\n",
        "                        'num_filters',\n",
        "                        values=[16, 32, 64],\n",
        "                        default=64,\n",
        "                ),\n",
        "                kernel_size=(1,3),\n",
        "                activation='relu',\n",
        "                input_shape=self.input_shape\n",
        "            )\n",
        "        )\n",
        "\n",
        "        model.add(\n",
        "            Dropout(rate=hp.Float(\n",
        "                'dropout_1',\n",
        "                min_value=0.0,\n",
        "                max_value=0.5,\n",
        "                default=0.25,\n",
        "                step=0.05,\n",
        "            ))\n",
        "        )\n",
        "        model.add(Flatten())\n",
        "        model.add(\n",
        "            Dense(\n",
        "                units=hp.Int(\n",
        "                    'units',\n",
        "                    min_value=32,\n",
        "                    max_value=512,\n",
        "                    step=32,\n",
        "                    default=128\n",
        "                ),\n",
        "                activation=hp.Choice(\n",
        "                    'dense_activation',\n",
        "                    values=['relu', 'tanh', 'sigmoid'],\n",
        "                    default='relu'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                rate=hp.Float(\n",
        "                    'dropout_2',\n",
        "                    min_value=0.0,\n",
        "                    max_value=0.5,\n",
        "                    default=0.25,\n",
        "                    step=0.05\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(Dense(self.n_outputs, activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(\n",
        "                hp.Float(\n",
        "                    'learning_rate',\n",
        "                    min_value=1e-4,\n",
        "                    max_value=1e-2,\n",
        "                    sampling='LOG',\n",
        "                    default=1e-3\n",
        "                )\n",
        "            ),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQEdgzB5CEtS"
      },
      "source": [
        "trainX, trainy, testX, testy = transform_dataset(trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPHIR6QDCimQ"
      },
      "source": [
        "n_timesteps, n_features, N_OUTPUTS = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\n",
        "n_steps, n_length = 4, 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoCYQT9DyUC"
      },
      "source": [
        "INPUT_SHAPE = (n_steps, 1, n_length, n_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nbNH1S9-2Rt"
      },
      "source": [
        "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
        "testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcdVxAI77R_L"
      },
      "source": [
        "Num_Epochs_Fit = 10\n",
        "Num_K_Folds = 5\n",
        "Model_Name_Conv = \"ConvLSTM\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAbkQ0eprgJM"
      },
      "source": [
        "X_ConvLSTM = np.concatenate((trainX, testX),axis=0)\n",
        "\n",
        "y_ConvLSTM = np.concatenate((trainy, testy),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cy3lfP2prBi"
      },
      "source": [
        "acc_score_ConvLSTM , avg_acc_score_ConvLSTM, Best_HP_ConvLSTM = K_Fold_CV(X, \n",
        "                                                                          y, \n",
        "                                                                          ConvLSTM,\n",
        "                                                                          Model_Name_Conv,\n",
        "                                                                          INPUT_SHAPE,\n",
        "                                                                          N_OUTPUTS,\n",
        "                                                                          Max_Trials,\n",
        "                                                                          Num_Epochs_Search,\n",
        "                                                                          Num_Epochs_Fit,\n",
        "                                                                          Num_K_Folds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC2mU1Bunxcj"
      },
      "source": [
        "BestModelConvLSTM, ConvLSTM_accuracy = evaluate_model(trainX,\n",
        "                                                      trainy,\n",
        "                                                      testX,\n",
        "                                                      testy,\n",
        "                                                      INPUT_SHAPE,\n",
        "                                                      N_OUTPUTS,\n",
        "                                                      Best_HP_ConvLSTM,\n",
        "                                                      ConvLSTM,\n",
        "                                                      Num_Epochs_Fit,\n",
        "                                                      batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUdh7wxeyx7Z"
      },
      "source": [
        "BestModelConvLSTM.save(\"/content/CrispCerebella/Models/Final_Model_ConvLSTM\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "800x2_JHWeLt"
      },
      "source": [
        "# CNN-LSTM\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLSUQ_KCqq5l"
      },
      "source": [
        "  # load all train\n",
        "trainX, trainy = datasetloader('train', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of training Data:\",trainX.shape, trainy.shape)\n",
        "# load all test\n",
        "testX, testy = datasetloader('test', '/content/CrispCerebella/Dataset/UCI HAR Dataset/')\n",
        "print(\"Shape of test Data:\",testX.shape, testy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFpIoFqtMtAb"
      },
      "source": [
        "class CNNLSTM(HyperModel):\n",
        "    def __init__(self, input_shape,n_outputs):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "    def build(self, hp):\n",
        "\n",
        "        model = keras.Sequential()\n",
        "        model.add(TimeDistributed(\n",
        "            Conv1D(\n",
        "                filters=hp.Choice(\n",
        "                        'num_filters_1',\n",
        "                        values=[16, 32, 64],\n",
        "                        default=64,\n",
        "                ),\n",
        "                kernel_size=3,\n",
        "                activation='relu',\n",
        "                input_shape=self.input_shape,\n",
        "            )\n",
        "          )   \n",
        "        )\n",
        "        model.add(TimeDistributed(\n",
        "            Conv1D(\n",
        "                filters=hp.Choice(\n",
        "                        'num_filters_2',\n",
        "                        values=[16, 32, 64],\n",
        "                        default=64,\n",
        "                ),\n",
        "                kernel_size=3,\n",
        "                activation='relu'\n",
        "            )\n",
        "          )   \n",
        "        )\n",
        "\n",
        "        model.add(TimeDistributed(Dropout(rate=hp.Float(\n",
        "                'dropout_1',\n",
        "                min_value=0.0,\n",
        "                max_value=0.5,\n",
        "                default=0.25,\n",
        "                step=0.05,\n",
        "            )\n",
        "           )\n",
        "          )\n",
        "        )\n",
        "      \n",
        "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(\n",
        "            LSTM(\n",
        "                units=hp.Int(\n",
        "                    'units_LSTM',\n",
        "                    min_value=32,\n",
        "                    max_value=512,\n",
        "                    step=32,\n",
        "                    default=128\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                rate=hp.Float(\n",
        "                    'dropout_2',\n",
        "                    min_value=0.0,\n",
        "                    max_value=0.5,\n",
        "                    default=0.25,\n",
        "                    step=0.05\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        model.add(\n",
        "            Dense(\n",
        "                units=hp.Int(\n",
        "                    'units',\n",
        "                    min_value=32,\n",
        "                    max_value=512,\n",
        "                    step=32,\n",
        "                    default=128\n",
        "                ),\n",
        "                activation=hp.Choice(\n",
        "                    'dense_activation',\n",
        "                    values=['relu', 'tanh', 'sigmoid'],\n",
        "                    default='relu'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        model.add(Dense(self.n_outputs, activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(\n",
        "                hp.Float(\n",
        "                    'learning_rate',\n",
        "                    min_value=1e-4,\n",
        "                    max_value=1e-2,\n",
        "                    sampling='LOG',\n",
        "                    default=1e-3\n",
        "                )\n",
        "            ),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaAE1ksEQdkn"
      },
      "source": [
        "trainX, trainy, testX, testy = transform_dataset(trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4-6TEk8ZUey"
      },
      "source": [
        "\tn_timesteps, n_features, N_OUTPUTS = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape data into time steps of sub-sequences\n",
        "\tn_steps, n_length = 4, 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcRDihf9qujV"
      },
      "source": [
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eePiNtzJZvIy"
      },
      "source": [
        "INPUT_SHAPE = (None, n_length,n_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swqNd5k17nfu"
      },
      "source": [
        "Num_Epochs_Fit = 10\n",
        "Num_K_Folds = 5\n",
        "Model_Name_CNN = \"CNNLSTM\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN5asJ_LrmQ9"
      },
      "source": [
        "X_CNNLSTM = np.concatenate((trainX, testX),axis=0)\n",
        "\n",
        "y_CNNLSTM = np.concatenate((trainy, testy),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUNT8kprsuY"
      },
      "source": [
        "acc_score_CNNLSTM , avg_acc_score_CNNLSTM,Best_HP_CNNLSTM = K_Fold_CV(X,\n",
        "                                                                      y,\n",
        "                                                                      CNNLSTM,\n",
        "                                                                      Model_Name_CNN,\n",
        "                                                                      INPUT_SHAPE,\n",
        "                                                                      N_OUTPUTS,\n",
        "                                                                      Max_Trials,\n",
        "                                                                      Num_Epochs_Search,\n",
        "                                                                      Num_Epochs_Fit,\n",
        "                                                                      Num_K_Folds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVcUSjR5omIn"
      },
      "source": [
        "BestModelCNNLSTM, CNNLSTM_accuracy = evaluate_model(trainX,\n",
        "                                                      trainy,\n",
        "                                                      testX,\n",
        "                                                      testy,\n",
        "                                                      INPUT_SHAPE,\n",
        "                                                      N_OUTPUTS,\n",
        "                                                      Best_HP_CNNLSTM,\n",
        "                                                      CNNLSTM,\n",
        "                                                      Num_Epochs_Fit,\n",
        "                                                      batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiIrLOPTr0ly"
      },
      "source": [
        "BestModelCNNLSTM.save(\"/content/CrispCerebella/Models/Final_Model_CNNLSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}